{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take all images for cats and dogs and convert to grayscale and resize to 56,56\n",
    "size = 56, 56\n",
    "for infile in glob.glob(\"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train/*.jpg\"):\n",
    "    outfile = os.path.splitext(infile)[0] + \".small\"    \n",
    "    file, ext = os.path.splitext(infile)\n",
    "    im = Image.open(infile).convert(\"L\")\n",
    "    out = im.resize((size))\n",
    "    out.save(outfile, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copy all newly created small cat images to a new folder\n",
    "#import shutil\n",
    "#for filename in glob.glob(\"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train/cat/*.small\"):\n",
    "    #shutil.copy(filename, \"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train/cat/small_cat\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (56, 56) L\n"
     ]
    }
   ],
   "source": [
    "#Display reduced gray scale images\n",
    "im = Image.open(\"cat.250.small\")\n",
    "print im.format, im.size, im.mode\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (56, 56) L\n"
     ]
    }
   ],
   "source": [
    "#Display reduced gray scale images\n",
    "im = Image.open(\"dog.1500.small\")\n",
    "print im.format, im.size, im.mode\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "image_size = 56\n",
    "pixel_depth = 255\n",
    "image_files = 25000\n",
    "dataset = np.ndarray(shape= (image_files, image_size, image_size), dtype= np.float32)\n",
    "target = np.ndarray(shape= (image_files), dtype= np.int_)\n",
    "num_images = 0\n",
    "for filename in glob.glob(\"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train/*.small\"):                         \n",
    "  \n",
    "  if num_images%5000 == 0: print(num_images)\n",
    "  try:\n",
    "      #image_data = (ndimage.imread(filename, flatten = True).astype(float)) \n",
    "      image_data = (ndimage.imread(filename, flatten = True).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      name = os.path.basename(filename)\n",
    "      if name.split(\".\")[0] == \"dog\":\n",
    "          target[num_images] = 1\n",
    "      else:\n",
    "          target[num_images] = 0\n",
    "      num_images = num_images + 1\n",
    "  except IOError as e:\n",
    "      print('Could not read:', filename, ':', e, '- it\\'s ok, skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dataset shape:', (25000, 56, 56))\n",
      "('Dataset Mean:', -0.039582334)\n",
      "('Dataset Max:', 0.50196081)\n",
      "('Dataset Min:', -0.49803922)\n",
      "('Target shape:', (25000,))\n",
      "('Target Mean:', 0.5)\n",
      "('Target Standard deviation:', 0.5)\n",
      "('Target Max:', 1)\n",
      "('Target Min:', 0)\n"
     ]
    }
   ],
   "source": [
    "print('Dataset shape:', dataset.shape)\n",
    "print('Dataset Mean:', np.mean(dataset))\n",
    "#print('Dataset Standard deviation:', np.std(dataset))\n",
    "print('Dataset Max:', np.amax(dataset))\n",
    "print('Dataset Min:', np.amin(dataset))\n",
    "print('Target shape:', target.shape)\n",
    "print('Target Mean:', np.mean(target))\n",
    "print('Target Standard deviation:', np.std(target))\n",
    "print('Target Max:', np.amax(target))\n",
    "print('Target Min:', np.amin(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomize dataset and target\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "all_dataset, all_labels = randomize(dataset, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD+CAYAAAAalrhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12775cf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display images and check for randomization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "n=12605\n",
    "image_array = (all_dataset[n])\n",
    "image_array.shape\n",
    "\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "print(all_labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dataset shape:', (25000, 56, 56))\n",
      "('Dataset Mean:', -0.039582387)\n",
      "('Dataset Max:', 0.50196081)\n",
      "('Dataset Min:', -0.49803922)\n",
      "('Target shape:', (25000,))\n",
      "('Target Mean:', 0.5)\n",
      "('Target Standard deviation:', 0.5)\n",
      "('Target Max:', 1)\n",
      "('Target Min:', 0)\n"
     ]
    }
   ],
   "source": [
    "## Check randomized array\n",
    "print('Dataset shape:', all_dataset.shape)\n",
    "print('Dataset Mean:', np.mean(all_dataset))\n",
    "#print('Dataset Standard deviation:', np.std(all_dataset))\n",
    "print('Dataset Max:', np.amax(all_dataset))\n",
    "print('Dataset Min:', np.amin(all_dataset))\n",
    "print('Target shape:', all_labels.shape)\n",
    "print('Target Mean:', np.mean(all_labels))\n",
    "print('Target Standard deviation:', np.std(all_labels))\n",
    "print('Target Max:', np.amax(all_labels))\n",
    "print('Target Min:', np.amin(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the data for future use\n",
    "\n",
    "#pickle file with 128 pixel images\n",
    "#pickle_file = 'catdog.pickle'\n",
    "\n",
    "pickle_file = 'catdog56.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'all_dataset': all_dataset,\n",
    "    'all_labels': all_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (25000, 56, 56), (25000,))\n"
     ]
    }
   ],
   "source": [
    "# For future runs load from pickled dataset\n",
    "pickle_file = 'catdog56.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    all_dataset = save['all_dataset']\n",
    "    all_labels = save['all_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', all_dataset.shape, all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the full dataset of 25k images into train - 20k images and test - 5k images \n",
    "from sklearn import cross_validation \n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "all_dataset, all_labels, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train dataset', (20000, 56, 56), (20000,))\n",
      "('test dataset', (5000, 56, 56), (5000,))\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset\", X_train.shape, y_train.shape)\n",
    "print(\"test dataset\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD+CAYAAAAalrhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14322f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check if split has happened properly\n",
    "n=2900\n",
    "image_array = (X_train[n])\n",
    "image_array.shape\n",
    "\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "print(y_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (20000, 56, 56, 1), (20000, 2))\n",
      "('Test set', (5000, 56, 56, 1), (5000, 2))\n"
     ]
    }
   ],
   "source": [
    "# Resize training and test dataset\n",
    "image_size = 56\n",
    "num_labels = 2\n",
    "num_channels = 1 # grayscale\n",
    "def reshape(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset_full, train_labels_full = reshape(X_train, y_train)\n",
    "test_dataset, test_labels = reshape(X_test, y_test)\n",
    "print('Training set', train_dataset_full.shape, train_labels_full.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Check how labels look\n",
    "n= 3105\n",
    "print(train_labels_full[n])\n",
    "print(np.argmax(train_labels_full[n]))\n",
    "#First column - Cat\n",
    "#Second column - Dog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define accuracy. Find closest integer and compare across predictions and labels\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((5000, 56, 56, 1), (5000, 2))\n"
     ]
    }
   ],
   "source": [
    "# create a small train dataset for testing algorithm\n",
    "train_dataset= train_dataset_full[:5000,:,:]\n",
    "train_labels= train_labels_full[:5000]\n",
    "print(train_dataset.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple convolution neural network - 2 layers with maxpool and 1 fully connected layer at the end\n",
    "\n",
    "batch_size = 16\n",
    "num_channels = 1\n",
    "num_labels = 2\n",
    "image_size = 56\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  def weight_variable(shape):\n",
    "      initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "      return tf.Variable(initial)\n",
    "\n",
    "  def bias_variable(shape):\n",
    "      initial = tf.constant(0.1, shape=shape)\n",
    "      return tf.Variable(initial)\n",
    "    \n",
    "  #Define convolution network\n",
    "  def conv2d(x, W):\n",
    "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "  def max_pool_2x2(x):\n",
    "      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "  \n",
    "# First Convolution Layer weights and biases\n",
    "  patch_size1 = 5\n",
    "  depth1 = 32\n",
    "  W_conv1 = weight_variable([patch_size1, patch_size1, num_channels, depth1])\n",
    "  b_conv1 = bias_variable([depth1])\n",
    "    \n",
    "# Second Convolution Layer weights and biases\n",
    "  patch_size2 = 5\n",
    "  depth2 = 64\n",
    "  W_conv2 = weight_variable([patch_size1, patch_size1, depth1, depth2])\n",
    "  b_conv2 = bias_variable([depth2])\n",
    "\n",
    "# Fully connected Layer\n",
    "#Image size is now image_size/4\n",
    "  num_neurons = 500\n",
    "  W_fc1 = weight_variable([(image_size/4) * (image_size/4) * depth2, num_neurons])\n",
    "  b_fc1 = bias_variable([num_neurons])\n",
    "\n",
    "#Output Layer\n",
    "  W_fc2 = weight_variable([num_neurons, num_labels])\n",
    "  b_fc2 = bias_variable([num_labels])\n",
    "                         \n",
    "                         \n",
    "  def model(data, keep_prob):  \n",
    "    # First convolution Layer\n",
    "      h_conv1 = tf.nn.relu(conv2d(data, W_conv1) + b_conv1)\n",
    "      h_pool1 = max_pool_2x2(h_conv1)\n",
    "    # Second convolution Layer\n",
    "      h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "      h_pool2 = max_pool_2x2(h_conv2)\n",
    "    #Fully connected Layer\n",
    "      shape = h_pool2.get_shape().as_list()\n",
    "      h_pool2_flat = tf.reshape(h_pool2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "      h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    #Droput to fully connecte layer\n",
    "      keep_prob = tf.placeholder(tf.float32)\n",
    "      h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    #Output Layer\n",
    "      return tf.matmul(h_fc1_drop, W_fc2) + b_fc2                   \n",
    "  \n",
    "  # Training computation.\n",
    "  # droput = 0.75\n",
    "  logits = model(tf_train_dataset, 0.75)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  # No dropout for test model \n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Placeholder_2', defined at:\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-0b375a284a30>\", line 77, in <module>\n    logits = model(tf_train_dataset, 0.75)\n  File \"<ipython-input-34-0b375a284a30>\", line 70, in model\n    keep_prob = tf.placeholder(tf.float32)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1274, in placeholder\n    name=name)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1522, in _placeholder\n    name=name)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-afbc6434f6e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     _, l, predictions = session.run(\n\u001b[0;32m---> 12\u001b[0;31m       [optimizer, loss, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minibatch loss at step %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 382\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    383\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 655\u001b[0;31m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 723\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op u'Placeholder_2', defined at:\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-0b375a284a30>\", line 77, in <module>\n    logits = model(tf_train_dataset, 0.75)\n  File \"<ipython-input-34-0b375a284a30>\", line 70, in model\n    keep_prob = tf.placeholder(tf.float32)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 1274, in placeholder\n    name=name)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1522, in _placeholder\n    name=name)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "num_steps = 300\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 100 == 0):\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        test_prediction.eval(), test_labels))\n",
    "  #print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
