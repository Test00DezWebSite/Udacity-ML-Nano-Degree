{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take all images for cats and dogs and resize to 227, 227. Keep color of image\n",
    "size = 227, 227\n",
    "for infile in glob.glob(\"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train/*.jpg\"):\n",
    "    outfile = os.path.splitext(infile)[0] + \".small\"    \n",
    "    file, ext = os.path.splitext(infile)\n",
    "    im = Image.open(infile)\n",
    "    out = im.resize((size), Image.ANTIALIAS)\n",
    "    out.save(outfile, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (227, 227) RGB\n"
     ]
    }
   ],
   "source": [
    "#Display reduced gray scale images\n",
    "im = Image.open(\"cat.250.small\")\n",
    "print im.format, im.size, im.mode\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'dog.1500.small'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-611d0b1cdfd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Display reduced gray scale images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog.1500.small\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/priyankadwivedi/anaconda/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2270\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2272\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'dog.1500.small'"
     ]
    }
   ],
   "source": [
    "#Display reduced gray scale images\n",
    "im = Image.open(\"dog.1500.small\")\n",
    "print im.format, im.size, im.mode\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "image_size = 227\n",
    "pixel_depth = 255\n",
    "image_files = 25000\n",
    "num_channels = 3\n",
    "dataset = np.ndarray(shape= (image_files, image_size, image_size, num_channels), dtype= np.float32)\n",
    "target = np.ndarray(shape= (image_files), dtype= np.int_)\n",
    "num_images = 0\n",
    "for filename in glob.glob(\"/Users/priyankadwivedi/Documents/Kaggle/CatvsDogs/train/*.small\"):                         \n",
    "  \n",
    "  if num_images%5000 == 0: print(num_images)\n",
    "  try:\n",
    "      #image_data = (ndimage.imread(filename, flatten = True).astype(float)) \n",
    "      image_data = (ndimage.imread(filename, flatten = False).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "      if image_data.shape != (image_size, image_size, num_channels):\n",
    "        raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "      dataset[num_images, :, :] = image_data\n",
    "      name = os.path.basename(filename)\n",
    "      if name.split(\".\")[0] == \"dog\":\n",
    "          target[num_images] = 1\n",
    "      else:\n",
    "          target[num_images] = 0\n",
    "      num_images = num_images + 1\n",
    "  except IOError as e:\n",
    "      print('Could not read:', filename, ':', e, '- it\\'s ok, skipping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Dataset shape:', dataset.shape)\n",
    "#print('Dataset Mean:', np.mean(dataset))\n",
    "#print('Dataset Standard deviation:', np.std(dataset))\n",
    "print('Dataset Max:', np.amax(dataset))\n",
    "print('Dataset Min:', np.amin(dataset))\n",
    "print('Target shape:', target.shape)\n",
    "print('Target Mean:', np.mean(target))\n",
    "print('Target Standard deviation:', np.std(target))\n",
    "print('Target Max:', np.amax(target))\n",
    "print('Target Min:', np.amin(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pickle to be safe\n",
    "# Pickle again\n",
    "os.chdir(r\"/Users/priyankadwivedi/Desktop/tensor/P5\")\n",
    "pickle_file = 'catdog227_temp.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'dataset': dataset,\n",
    "    'target': target,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randomize dataset and target\n",
    "def randomize(dataset, labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels\n",
    "all_dataset, all_labels = randomize(dataset, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Display images and check for randomization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "n=12605\n",
    "image_array = (all_dataset[n])\n",
    "image_array.shape\n",
    "\n",
    "plt.imshow(image_array, cmap='viridis', interpolation='None')\n",
    "print(all_labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the full dataset of 25k images into train - 20k images and test - 5k images \n",
    "from sklearn import cross_validation \n",
    "X_train, X_valid, y_train, y_valid = cross_validation.train_test_split(\n",
    "all_dataset, all_labels, test_size=0.2, random_state=252)\n",
    "print(\"train dataset\", X_train.shape, y_train.shape)\n",
    "print(\"Validation dataset\", X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check if split has happened properly\n",
    "n=2900\n",
    "image_array = (X_train[n])\n",
    "image_array.shape\n",
    "\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None')\n",
    "print(y_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split training again into test dataset\n",
    "from sklearn import cross_validation \n",
    "X_valid, X_test, y_valid, y_test = cross_validation.train_test_split(\n",
    "X_valid, y_valid, test_size=0.2, random_state=233)\n",
    "print(\"valid dataset\", X_valid.shape, y_valid.shape)\n",
    "print(\"test dataset\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resize training and test dataset\n",
    "image_size = 227\n",
    "num_labels = 2\n",
    "num_channels = 3 # grayscale\n",
    "def reshape(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset_full, train_labels_full = reshape(X_train, y_train)\n",
    "valid_dataset_full, valid_labels_full = reshape(X_valid, y_valid)\n",
    "test_dataset_full, test_labels_full = reshape(X_test, y_test)\n",
    "print('Training set', train_dataset_full.shape, train_labels_full.shape)\n",
    "print('Validation set', valid_dataset_full.shape, valid_labels_full.shape)\n",
    "print('Testing set', test_dataset_full.shape, test_labels_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle again\n",
    "os.chdir(r\"/Users/priyankadwivedi/Desktop/tensor/P5\")\n",
    "pickle_file = 'catdog227.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset_full': train_dataset_full,\n",
    "    'train_labels_full': train_labels_full,\n",
    "    'valid_dataset_full': valid_dataset_full,\n",
    "    'valid_labels_full': valid_labels_full,\n",
    "    'test_dataset_full': test_dataset_full,\n",
    "    'test_labels_full': test_labels_full,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
